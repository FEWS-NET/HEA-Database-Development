stages:
  - lint
#  - build_then_test
#  - report
#  - deploy

# Use a base image that contains Docker (with compose plugin)
image: "docker:dind"

# Make sure that the container is allowed access to use Docker to build and run new images
services:
  - docker:dind

variables:
  CLIENT: "fnt"
  APP: "fdw"
  ENV: "tst"
  SUPPORT_EMAIL_ADDRESS: "helpdesk@fews.net"
  DATABASE_URL: "postgis://fntfdwtst:testpass@db:5432/fntfdwtst"
  PGDATABASE: "fntfdwtst"
  PGHOST: "db"
  PGPASSWORD: "testpass"
  PGPORT: "5432"
  PGUSER: "fdwtst"
  PIP_INDEX_URL: "https://pypi.python.org/simple/"
  SECRET_KEY: ${SECRET_KEY}
  KILUIGI_INTERMEDIATETARGET_BACKEND_CLASS: kiluigi.targets.ExpiringLocalTarget
  KILUIGI_INTERMEDIATETARGET_ROOT_PATH: /usr/src/app/media/pipelines/intermediate_targets
  KILUIGI_FINALTARGET_BACKEND_CLASS: kiluigi.targets.LocalTarget
  KILUIGI_FINALTARGET_ROOT_PATH: /usr/src/app/media/pipelines/final_targets
  KILUIGI_REPORTTARGET_BACKEND_CLASS: kiluigi.targets.LocalTarget
  KILUIGI_REPORTTARGET_ROOT_PATH: /usr/src/app/media/pipelines/reports
  DOCKER_TLS_CERTDIR: "/certs/client"
  GIT_SUBMODULE_STRATEGY: recursive
  GIT_DEPTH: 0
  COMPOSE_PROJECT_NAME: ci-${APP}-${CI_PIPELINE_ID}
  COMPOSE_FILE: docker-compose.yml:docker-compose.ci.yml:docker-compose.utils.yml
  BUILD_IMAGES: "app db nginx"
  AWS_DEFAULT_REGION: "us-east-1"
  ECS_CLUSTER: "fnt_ecs"
  DOCKER_HUB_AUTH_CONFIG: ${DOCKER_HUB_AUTH_CONFIG}

lint:
  # Do a simple lint as the first stage to check code style, etc.
  # so that we can fail fast on easy to detect errors without having
  # to wait for a Docker build
  image: python:3.11
  before_script:
    - pip install -r requirements/lint.txt
  script:
    - ruff .
    - black --check .
    - isort --check .
  stage: lint
  except:
    - docs

test_branch:
  # Build and test in a single step so that we don't have to wait
  # while we push the built containers to a Registry and then wait
  # again while we pull them in later CI steps.
  before_script:
    # Docker hub is rate-limiting unauthenticated users, so we have to
    # authenticate: https://www.docker.com/increase-rate-limits
    - mkdir -p $HOME/.docker
    - echo ${DOCKER_HUB_AUTH_CONFIG} > $HOME/.docker/config.json
    # Make sure the VERSION.txt reflects the actual commit we are building
    - echo "${CI_COMMIT_REF_NAME}-${CI_COMMIT_SHORT_SHA}" > VERSION.txt
    # Pull the current images so we can reuse the cached layers, allowing for the fact they might not exist yet
    - echo Using registry image ${CI_REGISTRY_IMAGE}
    - echo ${CI_DEPLOY_PASSWORD} | docker login -u ${CI_DEPLOY_USER} --password-stdin ${CI_REGISTRY}
    - for SERVICE in ${BUILD_IMAGES}; do (docker pull ${CI_REGISTRY_IMAGE}/${SERVICE}:edge | grep -i -e 'Pulling from' -e Digest -e Status -e Error) || true; done
    - for SERVICE in ${BUILD_IMAGES}; do (docker pull ${CI_REGISTRY_IMAGE}/${SERVICE}:latest | grep -i -e 'Pulling from' -e Digest -e Status -e Error) || true; done
    # Build the images
    - docker compose build
    # Save the images to speed up future builds
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:edge; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:edge | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    # Start the service containers
    - docker compose up -d db minio redis celery_slow celery_medium celery_fast celery_luigi
    # Wait for containers to be ready
    - echo $`date` Wait for containers to be ready
    - docker compose run -e TARGETS=db:5432,minio:9000,redis:6379 -e TIMEOUT=90 wait
    - echo $`date` Containers ready
    - docker compose exec -T db pg_config --version
  script:
    # Use run instead of up because we want docker-compose to return the exit code
    # Exclude the perf test and run it separately, so that we can run it in parallel with the rest of the tests
    - docker compose run --name ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME} app --keepdb --exclude-tag=perf 2>&1 | tee test_output.log
    # Test that the output is "clean"
    - docker compose run --rm --volume=$(pwd)/test_output.log:/usr/src/app/test_output.log --entrypoint /usr/src/app/manage.py app check_test_output test_output.log
    # Save a "review" Docker image
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:test-${CI_COMMIT_REF_SLUG}; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:test-${CI_COMMIT_REF_SLUG} | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:test-${CI_COMMIT_REF_SLUG} >/dev/null; done
    # Create a Docker Compose file compatible with ecs-cli (use a multi-line string to escape the :'s) for use in deploy_review below
    - >
      docker compose -f docker-compose.yml -f docker-compose.review.yml config --no-interpolate > docker-compose.ecs.yml
  after_script:
    # Save docker logs as artifacts
    - docker compose logs --no-color > ./docker.log
    - for SERVICE in $(docker compose ps --services); do docker compose logs --no-color ${SERVICE} > ./docker.${SERVICE}.log; done
    # Copy the artifacts out of the Docker container to project directory
    - docker cp ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME}:/usr/src/app/log ./
    - docker cp ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME}:/usr/src/app/coverage.txt ./
    # Save the database schema as an artifact
    - docker compose run --no-deps --rm --entrypoint dbtoyaml app --no-owner --no-privileges test_${PGDATABASE} > schema.yml
    - diff pyrseas/schema.yaml schema.yml > schema.diff
    # Clean up
    - docker compose down --volumes 2>/dev/null
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:edge >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:latest >/dev/null; done
  stage: build_then_test
  artifacts:
    paths:
      - log
      - coverage.txt
      - docker*.log
      - docker-compose.ecs.yml
      - ecs-params.yml
      - schema.diff
      - schema.yml
      - test_output.log
    reports:
      junit: log/test_results.xml
    when: always
    expire_in: 1 week
  except:
    - branding
    - docs
    - tags
    - main

test_keepdb:
  extends: test_branch
  script:
    # Use run instead of up because we want docker-compose to return the exit code
    # Run a TransactionTestCase and retain the database. TransactionTestCase truncates all the tables after running the test.
    # This leaves a database with migrations already run, and tables existing, but without any data that might have been created by those migrations.
    - docker compose run --rm app --keepdb warehouse.tests.test_admin.DataUploadAdminTestCase
    # Run the tests again, to ensure that they set up all required test data and consequently work correctly with a truncated database
    - docker compose run --name ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME} app --keepdb --exclude-tag=perf 2>&1 | tee test_output.log
  except:
    - docs

test_main:
  extends: test_branch
  script:
    # Use run instead of up because we want docker-compose to return the exit code
    - docker compose run --name ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME} -e CHECK_SAFETY=1 -e TEST_OUTPUT_VERBOSE=2 app --keepdb --exclude-tag=perf 2>&1 | tee test_output.log
    # Test that the output is "clean"
    - docker compose run --rm --volume=$(pwd)/test_output.log:/usr/src/app/test_output.log --entrypoint /usr/src/app/manage.py app check_test_output test_output.log
    # Save a "latest" Docker image
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:latest; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:latest | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:latest >/dev/null; done
  only:
    - main
  except: []

test_tag:
  before_script:
    # Docker hub is rate-limiting unauthenticated users, so we have to
    # authenticate: https://www.docker.com/increase-rate-limits
    - mkdir -p $HOME/.docker
    - echo ${DOCKER_HUB_AUTH_CONFIG} > $HOME/.docker/config.json
    # Pull new images and disable the cache so we pick up any security fixes
    - echo ${CI_DEPLOY_PASSWORD} | docker login -u ${CI_DEPLOY_USER} --password-stdin ${CI_REGISTRY}
    - docker compose build --pull --force-rm --no-cache
    # Save the images to speed up future builds
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:edge; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:edge | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    # Start the service containers
    - docker compose up -d db minio redis celery_slow celery_medium celery_fast celery_luigi
    # Wait for containers to be ready
    - docker compose run -e TARGETS=db:5432,minio:9000,redis:6379 -e TIMEOUT=60 wait
  script:
    # Use run instead of up because we want docker-compose to return the exit code
    - docker compose run --name ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME} -e CHECK_SAFETY=1 -e TEST_OUTPUT_VERBOSE=2 app --keepdb --exclude-tag=perf 2>&1 | tee test_output.log
    # Test that the output is "clean"
    - docker compose run --rm --volume=$(pwd)/test_output.log:/usr/src/app/test_output.log --entrypoint /usr/src/app/manage.py app check_test_output test_output.log
    # Create the prod image that doesn't contain the test requirements
    - docker compose -f docker-compose.yml build app
    # Tag the prod image
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:${CI_BUILD_TAG}; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:${CI_BUILD_TAG} | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:latest; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:latest | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
    - for SERVICE in ${BUILD_IMAGES}; do docker tag ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest ${CI_REGISTRY_IMAGE}/${SERVICE}:stable; done
    - for SERVICE in ${BUILD_IMAGES}; do docker push ${CI_REGISTRY_IMAGE}/${SERVICE}:stable | grep -i -e 'The push refers to' -e Digest -e Status -e Error; done
  after_script:
    # Save docker logs as artifacts
    - docker compose logs --no-color > ./docker.log
    - for SERVICE in $(docker compose ps --services); do docker compose logs --no-color ${SERVICE} > ./docker.${SERVICE}.log; done
    # Copy the artifacts out of the Docker container to project directory
    - docker cp ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME}:/usr/src/app/log ./
    - docker cp ci-${APP}-${CI_PIPELINE_ID}-${CI_JOB_NAME}:/usr/src/app/coverage.txt ./
    # Save the database schema as an artifact
    - docker compose run --no-deps --rm --entrypoint dbtoyaml app --no-owner --no-privileges test_${PGDATABASE} > schema.yml
    - diff pyrseas/schema.yaml schema.yml > schema.diff
    # Clean up
    - docker compose down --volumes 2>/dev/null
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ci-${APP}-${CI_PIPELINE_ID}-${SERVICE}:latest >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:edge >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:latest >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:stable >/dev/null; done
    - for SERVICE in ${BUILD_IMAGES}; do docker image rm ${CI_REGISTRY_IMAGE}/${SERVICE}:${CI_BUILD_TAG} >/dev/null; done
  stage: build_then_test
  artifacts:
    expire_in: 27 weeks
  only:
    - tags

report:
  # Produce combined coverage report
  image: python:3.11
  before_script:
    # Use the version from requirements/test.txt
    - pip install coverage==5.0.4
  script:
    - cp ./log/.coverage.* ./
    - coverage combine
    - coverage report --skip-covered
    - coverage report --show-missing > ./coverage.txt
  stage: report
  artifacts:
    paths:
      - log
      - coverage.txt
  except:
    - docs
